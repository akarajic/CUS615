{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akarajic/CUS615/blob/main/ProblemSet8/FINAL_Problem_set_08_Exam_Project_CUS615_(1)_(1)_(2).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I81n6Tk2bTd3"
      },
      "source": [
        "This notebook is part the of **Dr. Christoforos Christoforou's** course materials. You may not, nor may you knowingly allow others to reproduce or distribute lecture notes, course materials or any of their derivatives without the instructor's express written consent."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJd26bpK54JR"
      },
      "source": [
        "# Exam Project\n",
        "**Professor**: Dr. Christoforos Christoforou\n",
        "\n",
        "The objective of this project is to reproduce the data analysis method presented in the paper:\n",
        "\n",
        "* **\"Mining Big Data to Extract Patterns and Predict Real-Life Outcomes\"**\n",
        "by Michal Kosinski, Yilun Wang, Himabindu Lakkaraju, and Jure Leskovec.\n",
        "\n",
        "\n",
        "You must implement the analysis using python code. This notebook provides you with the starting code to load the data and guides you through the requirement and each sub-task of the analysis. To complete this project you are expected to:\n",
        "\n",
        "1. Carefully read the paper.\n",
        "2. Refer the class lecture where this paper was discussed in detail.\n",
        "3. Research various python libraries and utility functions needed to implement your analysis.\n",
        "4. Complete all the challenges outlined in this notebook.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BA45dOL-iEkE"
      },
      "source": [
        "## Student Information \n",
        "Complete your information in the form provided below. This is visible in colab. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NaAt15_OiVnw",
        "cellView": "form"
      },
      "source": [
        "#@title Strudent Information \n",
        "student_name = \"Adna Karajic\" #@param {type:\"string\"}\n",
        "course_code = \"CUS 615\" #@param {type:\"string\"}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZqGbeNmFGCCU"
      },
      "source": [
        "## Starter code - Configuring the analysis environment\n",
        "The code cells below provide you a starting code to setup the environment for you to complete this project's tasks.\n",
        "\n",
        "In particular, the code downloads the three dataset associated with this project and stores them in the folder `/content/sample_data/`. The data files from the paper comprise the `likes.csv` file, the `users.csv` file and the `users-likes.csv`; description of each data file is availabile in the paper.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AB33C_sJ5p4H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5013e56d-e786-46e1-b5bc-e13a31129328"
      },
      "source": [
        "#\n",
        "# Run this sell to download the data for your analysis. \n",
        "#\n",
        "!wget -O /content/sample_data/sample_dataset.zip https://osf.io/9m87k/download\n",
        "!unzip /content/sample_data/sample_dataset.zip -d /content/sample_data/\n"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2023-05-03 00:28:22--  https://osf.io/9m87k/download\n",
            "Resolving osf.io (osf.io)... 35.190.84.173\n",
            "Connecting to osf.io (osf.io)|35.190.84.173|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 FOUND\n",
            "Location: https://files.osf.io/v1/resources/fuqjg/providers/osfstorage/5e946850f1353503a3d52f24?action=download&direct&version=1 [following]\n",
            "--2023-05-03 00:28:22--  https://files.osf.io/v1/resources/fuqjg/providers/osfstorage/5e946850f1353503a3d52f24?action=download&direct&version=1\n",
            "Resolving files.osf.io (files.osf.io)... 35.186.214.196\n",
            "Connecting to files.osf.io (files.osf.io)|35.186.214.196|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 314322145 (300M) [application/octet-stream]\n",
            "Saving to: ‘/content/sample_data/sample_dataset.zip’\n",
            "\n",
            "/content/sample_dat 100%[===================>] 299.76M  69.1MB/s    in 4.2s    \n",
            "\n",
            "2023-05-03 00:28:27 (70.9 MB/s) - ‘/content/sample_data/sample_dataset.zip’ saved [314322145/314322145]\n",
            "\n",
            "Archive:  /content/sample_data/sample_dataset.zip\n",
            "replace /content/sample_data/likes.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_k8ynI123ng",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96770eb9-8e0e-417a-9931-7298a0556f16"
      },
      "source": [
        "#\n",
        "# Install additional package not available in colab.\n",
        "#\n",
        "!pip install factor_analyzer"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: factor_analyzer in /usr/local/lib/python3.10/dist-packages (0.4.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from factor_analyzer) (1.10.1)\n",
            "Requirement already satisfied: pre-commit in /usr/local/lib/python3.10/dist-packages (from factor_analyzer) (3.3.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from factor_analyzer) (1.2.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from factor_analyzer) (1.5.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from factor_analyzer) (1.22.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->factor_analyzer) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->factor_analyzer) (2022.7.1)\n",
            "Requirement already satisfied: cfgv>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pre-commit->factor_analyzer) (3.3.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from pre-commit->factor_analyzer) (6.0)\n",
            "Requirement already satisfied: nodeenv>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from pre-commit->factor_analyzer) (1.7.0)\n",
            "Requirement already satisfied: identify>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pre-commit->factor_analyzer) (2.5.23)\n",
            "Requirement already satisfied: virtualenv>=20.10.0 in /usr/local/lib/python3.10/dist-packages (from pre-commit->factor_analyzer) (20.23.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->factor_analyzer) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->factor_analyzer) (3.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nodeenv>=0.11.1->pre-commit->factor_analyzer) (67.7.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->factor_analyzer) (1.16.0)\n",
            "Requirement already satisfied: distlib<1,>=0.3.6 in /usr/local/lib/python3.10/dist-packages (from virtualenv>=20.10.0->pre-commit->factor_analyzer) (0.3.6)\n",
            "Requirement already satisfied: platformdirs<4,>=3.2 in /usr/local/lib/python3.10/dist-packages (from virtualenv>=20.10.0->pre-commit->factor_analyzer) (3.3.0)\n",
            "Requirement already satisfied: filelock<4,>=3.11 in /usr/local/lib/python3.10/dist-packages (from virtualenv>=20.10.0->pre-commit->factor_analyzer) (3.12.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aO_u3jLnJ6ut"
      },
      "source": [
        "#\n",
        "# You will likely need the following python packages when implementing this project.\n",
        "# Add any additional package as you deem necessary \n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.sparse import csr_matrix\n",
        "from scipy.sparse.linalg import svds, eigs\n",
        "from factor_analyzer import Rotator\n",
        "\n",
        "# Additional package you want to use:\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qc6GFQPhKTUn"
      },
      "source": [
        "## Challenge 1 : Load the data into dataframes\n",
        "In this challenge you are expected to load the data from the raw files into the following variables:\n",
        "-  `users` : should reference a dataframe with the data in the `users.csv` file\n",
        "-  `likes` : should reference a dataframe with the data in the `likes.csv` file\n",
        "-  `ul` : should reference a dataframe with the data in `users.csv` file\n",
        "\n",
        "Then print the top 10 rows of reach dataframe."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7jYTqf_Mabo"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "users = pd.read_csv(\"./sample_data/users.csv\")\n",
        "likes = pd.read_csv(\"./sample_data/likes.csv\")\n",
        "ul = pd.read_csv(\"./sample_data/users-likes.csv\")\n"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tlspDtjMf89",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "364131dc-95f6-4f3a-f08d-a7afecb4935a"
      },
      "source": [
        "#\n",
        "# Answer summary cell: Print the top 10 row from each datafame. \n",
        "# \n",
        "\n",
        "print(\"Users: \", users.head())\n",
        "print(\"Likes: \", likes.head())\n",
        "print(\"User-Likes: \", ul.head())"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Users:                               userid  gender  age  political   ope   con   ext  \\\n",
            "0  54f34605aebd63f7680e37ffd299af79       0   33        0.0  1.26  1.65  1.17   \n",
            "1  86399f8c44ba54224b2e60177ca89fa9       1   35        0.0  1.07  0.17 -0.14   \n",
            "2  84fab50f3c60d1fdc83aa91b5e584a78       1   36        0.0  0.89  1.28  0.86   \n",
            "3  f3b8fdaccce12ef6352bfad4d6052fe9       0   39        NaN  0.33 -1.01 -0.33   \n",
            "4  8b06ea5e9cb87c61da387995450607f7       0   31        NaN  0.15  0.47  1.17   \n",
            "\n",
            "    agr   neu  \n",
            "0 -1.76  0.61  \n",
            "1  1.49  0.30  \n",
            "2  1.07  0.99  \n",
            "3 -0.68  0.92  \n",
            "4 -1.01 -0.32  \n",
            "Likes:                               likeid  \\\n",
            "0  3c1636c878e6eb2acfd00c6b61086e38   \n",
            "1  feca46ddb8ef04f86172ace0cb7e004c   \n",
            "2  b65f46d64c688fe98bdbcf93a76a71fc   \n",
            "3  9c5c8bb82d2cd46fbd7582f944fe370e   \n",
            "4  2d82fa84ad79b085dc516dde154327a2   \n",
            "\n",
            "                                                name  \n",
            "0                               REIGN by Paul Gibson  \n",
            "1                   Cupcake Wishes & Birthday Dreams  \n",
            "2       Yo también me rei de la caída de otro jejeje  \n",
            "3  Abraham Joshua Heschel Day School- Alumni Network  \n",
            "4                           Kennesaw Farmer's Market  \n",
            "User-Likes:                               userid                            likeid\n",
            "0  71bc7c0901488aec6d30f0add257e7c5  3c1636c878e6eb2acfd00c6b61086e38\n",
            "1  978ab8e90c4d6ad1a48ef5c973b62f4d  feca46ddb8ef04f86172ace0cb7e004c\n",
            "2  85123b0e358907725cf19a2cb0ec3983  b65f46d64c688fe98bdbcf93a76a71fc\n",
            "3  ce110562b3e2f7e5cad3775b32d9caa5  b65f46d64c688fe98bdbcf93a76a71fc\n",
            "4  8188d20745471273fa69ba44a5b28473  b65f46d64c688fe98bdbcf93a76a71fc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJYv5EFuMfkL"
      },
      "source": [
        "## Challenge 2: Create the sparse user-likes matrix \n",
        "Create a **sparse matrix** that stores the data for the user-likes associations as described in the paper. The name of the user-likes matrix must be `M`, to keep the naming convention used in the paper. It is important that to store the data in a sparse matrix; you might need to research the topic of using sparse matrices in python (i.e. look at the `scipy.sparse` package and the `csr_matrix` class). *Hint: For this challenge,  you might find  the `merge` method from `pandas` library useful*. \n",
        "\n",
        "Once you create the matrix print its shape on the answer summary cell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QnI9ocfkYox-"
      },
      "source": [
        "from scipy.sparse import csr_matrix\n",
        "\n",
        "#Merge the 'ul' and 'users' dataframes on the 'userid' column and get the 'index' column\n",
        "rows = pd.merge(left=ul, right=users.reset_index(), on='userid', how=\"left\")['index']\n",
        "\n",
        "#Merge the 'ul' and 'likes' dataframes on the 'likeid' column and get the 'index' column\n",
        "columns = pd.merge(left=ul, right=likes.reset_index(), on=\"likeid\", how=\"left\")['index']\n",
        "\n",
        "M = csr_matrix((np.ones((len(ul))), (rows,columns)))"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckYGEacxYvho",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89faacfe-513f-4104-b94f-cc757dff2f54"
      },
      "source": [
        "print(\"Shape of the Raw Matrix M:\", M.shape)\n"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of the Raw Matrix M: (110728, 1580284)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKJldPiWY5Tr"
      },
      "source": [
        "## Challege 3: Trim the sparse user-likes matrix M.\n",
        "The paper calls for the matrix `M` to be trimmed (i.e. to remove users which did not like a minimum number of posts and posts that did not receive a minimum number of likes). In this challenge, you are expected to implement the trimming preprocessing step as described in the paper. The resulting matrix must be a sparse matrix. *Hint: you might want to research to index slice sparse matrices in python*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_M8CC9-cXZs"
      },
      "source": [
        "y=users.political\n",
        "\n",
        "#Remove rows and columns where the sum of values is less than 50 and 150 respectively\n",
        "while True:\n",
        "    i = M.shape[0] + M.shape[1]\n",
        "    y = y[np.array(np.sum(M, axis=1) >= 50).flatten()]\n",
        "    M = M[np.array(np.sum(M, axis=1) >= 50).flatten(), :]\n",
        "    M = M[:,np.array(np.sum(M, axis=0) >= 150).flatten()]\n",
        "    if i == (M.shape[0] + M.shape[1]):\n",
        "        break\n",
        "\n",
        "y= pd.DataFrame(y).reset_index(drop=True)"
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ywuRl88caaG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "240c6e50-1d92-491f-9f41-108cfd30483c"
      },
      "source": [
        "print(\"Shape of the Trimmed Matrix M:\", M.shape)"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of the Trimmed Matrix M: (19742, 8523)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CPCmSbfCcs4P"
      },
      "source": [
        "## Challenge 4:  Split the sparse matrix into a training and testing matrices\n",
        "To build a prediction model the paper calls for separating the data matrix (i.e. the user-like matrix) into a training and testing matrices. As part of this challenge, you need to create a training matrix `M_train` that includes the preferences of 80% of the users, and a testing matrix `M_test` that include the preferences of the remaining 20% of the users in the dataset. Both matrices `M_train` and `M_test` must be stored as sparse matrices. User will be randomly assigned to the training or testing set.\n",
        "\n",
        "Print the shapes of the `M_train` and `M_test` matrices.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1avbiXTygvz"
      },
      "source": [
        "import numpy as np\n",
        "from scipy.sparse import csr_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#Split the row indices into training and test sets\n",
        "M_train, M_test, y_train, y_test = train_test_split(M, y, train_size=0.8, random_state=42)"
      ],
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbTijUQ0ykDn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0b1f284-b5d3-4b6f-9c38-f8f840afe70a"
      },
      "source": [
        "#\n",
        "# Answer summary cell: Print the shapes of M_train, M_test and M matrices.  \n",
        "# \n",
        "\n",
        "print(M_train.shape)\n",
        "print(M_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(15793, 8523)\n",
            "(3949, 8523)\n",
            "(15793, 1)\n",
            "(3949, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cPhHjAdciZP"
      },
      "source": [
        "## Challege 5 : Reduce the dimensionality of the M_train matrix using SVD\n",
        "\n",
        "In this challenge, you must use singular value decomposition (SVD) to reduce the dimensionality of the training matrix `M_train`. Remember that `M_train` is encoded as a sparse matrix so you would need to use an appropriate implementation of the SVD for sparse matrices. Your output should be the matrices `U`, `S` and `Vt` that correspond to the left singular vectors, the singular values, and the right singular vectors, respectively. You must specify a parameter `k` that defines the number of reduced dimensions you want to keep.\n",
        "\n",
        "Print the shapes of the `U`, `S` and `Vt` matrices and the value you selected for parameter `k`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--NlzhH21mWj"
      },
      "source": [
        "from scipy.sparse.linalg import svds\n",
        "import numpy as np\n",
        "\n",
        "# Specify the number of dimensions to keep\n",
        "k = 200\n",
        "\n",
        "# Compute the SVD of M_train\n",
        "U, S, Vt = svds(M_train, k=k, random_state=12)"
      ],
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZEtb9wsn1mzZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "887e0e8b-26bc-40ae-b534-9646a55d6b48"
      },
      "source": [
        "print(U.shape)\n",
        "print(S.shape)\n",
        "print(Vt.shape)\n",
        "print(k)"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(15793, 200)\n",
            "(200,)\n",
            "(200, 8523)\n",
            "200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJa9qQVr1vmv"
      },
      "source": [
        "## Challege 6 : Use the varimax algorithm to rotate the SVD dimensions. \n",
        "Use the varimax algorithm to rotate the SVD dimensions as described in the paper. A good python library that implements varimax algorithm is the `factor_analyzer` and its `Rotator` class (already installed in this notebook for your in the started cell above); i.e. using `rotator = Rotator(method='varimax')`. Store the varimax SVD into the matrices `U_rot` and `V_rot` respectively. *Hint: you can apply varimax of `Vt` to get `V_rot` and then multiply `M` by  `Vt_rot` to obtain the `U_rot` (as done in the paper); you might want to research hot to user the `Rotator` class*. \n",
        "\n",
        "Print the shapes of the matrices `U_rot` and `V_rot`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxGmf_MN4KH0"
      },
      "source": [
        "from factor_analyzer.rotator import Rotator\n",
        "\n",
        "# Create a Rotator object with varimax method\n",
        "rotator = Rotator(method='varimax')\n",
        "\n",
        "# Fit the Rotator object on Vt matrix to obtain V_rot\n",
        "V_rot = rotator.fit_transform(Vt.T)\n",
        "\n",
        "# Multiply M by the rotated Vt matrix to obtain U_rot\n",
        "U_rot = M.dot(V_rot)"
      ],
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_2U3n2X4h_0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f6ddbeb-35f5-4aca-b40b-8b978bc14637"
      },
      "source": [
        "print(V_rot.shape)\n",
        "print(U_rot.shape)"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(8523, 200)\n",
            "(19742, 200)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lp0BpsHd4wfg"
      },
      "source": [
        "## Challenge 7 : Train two predictive model to predict the political  affilication of users.\n",
        "Build a predictive model that predicts the political affiliation of the users given the user's post preferences (as those are captured in the paper's dataset). To train your model you can use data from matrix `M_train` only. You are expected to use two different predictive models of your choice (i.e. Knn, SVM, Logistic Regression or some other model of your choice).\n",
        "\n",
        "As part of this challenge you are expected to:\n",
        "- Apply any necessary preprocessing to handle missing values.\n",
        "- The models must be applied on the reduced-dimensional feature generated by your analysis above (i.e. use the singular rotated singular dimensions)\n",
        "- Use cross-validation for model selection (i.e. to identify optimal parameters for your model, or any meta-parameters)\n",
        "- Report training and cross-validation performance of the two models as well as the optimal parameters for your model identified by cross validation. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iiQ_wRcs7pA7"
      },
      "source": [
        "**FIRST MODEL TRAINING: Use the cells below to train the predictive model using the first model you selected.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WK6Yd4hf7fAA"
      },
      "source": [
        "#\n",
        "# Use this cell to train the first model you selected for challenge 7. \n",
        "# Add additional cells as needed below this cell.\n",
        "#\n",
        "import pandas as pd\n",
        "\n",
        "#Calculate the  product of M_train and the transpose of Vt and assign it to X_train\n",
        "X_train=M_train.dot(Vt.T)\n",
        "\n",
        "#Convert X_train into a DataFrame object and add y_train as a column\n",
        "X_train=pd.DataFrame(X_train)\n",
        "X_train['y']=y_train\n",
        "\n",
        "#Remove rows with null values in the y column\n",
        "X_train=X_train[X_train['y'].isnull()==False]\n",
        "X_train['y'].isnull()\n",
        "\n",
        "#Assign the y_train column to the y_train variable and drop the y column from X_train\n",
        "y_train=X_train['y']\n",
        "X_train=X_train.drop('y', axis=1)"
      ],
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uHxGNOFf83pO"
      },
      "source": [
        "**FIRST MODEL ACCURACY REPORT: Use the cell below to report on the accuracy of your first model**\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# Define parameter grid for SVM\n",
        "param_grid = {'C': [0.01, 0.1, 1, 10],\n",
        "              'gamma': [0.01, 0.1, 1, 10]}\n",
        "\n",
        "# Initialize SVM model\n",
        "svm_model = SVC(kernel='rbf', random_state=42)\n",
        "\n",
        "# Perform grid search with cross-validation to find optimal hyperparameters\n",
        "svm_grid_search = GridSearchCV(svm_model, param_grid, cv=5)\n",
        "svm_grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best hyperparameters and the corresponding mean test score\n",
        "best_params = svm_grid_search.best_params_\n",
        "best_score = svm_grid_search.best_score_\n",
        "\n",
        "# Train the SVM model with the best hyperparameters on the full training set\n",
        "svm_model = SVC(kernel='rbf', C=best_params['C'], gamma=best_params['gamma'], random_state=42)\n",
        "\n",
        "print(\"Best parameters:\", best_params)\n",
        "print(\"Best cross-validation score:\", best_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nXTscX0Lblry",
        "outputId": "981dc988-8fb5-4118-9f02-54d87ff829dc"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters: {'C': 1, 'gamma': 0.01}\n",
            "Best cross-validation score: 0.7017763327355524\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zrkRGd1t-ISp"
      },
      "source": [
        "**SECOND MODEL TRAINING: Use the cells below to train the predictive model using the second model you selected.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GR8wUcci-Lnj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "ae57ef0c-e44c-4b87-b6df-9cdeedcae486"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define the range of hyperparameters for KNN\n",
        "param_grid = {\n",
        "    'n_neighbors': range(1,100),\n",
        "    'weights': ['uniform', 'distance'],\n",
        "    'p': [1, 2]\n",
        "}\n",
        "\n",
        "# Create a KNN model\n",
        "knn = KNeighborsClassifier()\n",
        "\n",
        "# Perform grid search cross-validation to select the optimal hyperparameters\n",
        "grid_search = GridSearchCV(knn, param_grid, cv=5, n_jobs=-1, scoring='accuracy')\n",
        "grid_search.fit(X_train, y_train)"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, estimator=KNeighborsClassifier(), n_jobs=-1,\n",
              "             param_grid={'n_neighbors': range(1, 100), 'p': [1, 2],\n",
              "                         'weights': ['uniform', 'distance']},\n",
              "             scoring='accuracy')"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=KNeighborsClassifier(), n_jobs=-1,\n",
              "             param_grid={&#x27;n_neighbors&#x27;: range(1, 100), &#x27;p&#x27;: [1, 2],\n",
              "                         &#x27;weights&#x27;: [&#x27;uniform&#x27;, &#x27;distance&#x27;]},\n",
              "             scoring=&#x27;accuracy&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=KNeighborsClassifier(), n_jobs=-1,\n",
              "             param_grid={&#x27;n_neighbors&#x27;: range(1, 100), &#x27;p&#x27;: [1, 2],\n",
              "                         &#x27;weights&#x27;: [&#x27;uniform&#x27;, &#x27;distance&#x27;]},\n",
              "             scoring=&#x27;accuracy&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TSPXB9JO9JKj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8RcnRV85-SkD"
      },
      "source": [
        "**SECOND MODEL ACCURACY REPORT: Use the cell below to report on the accuracy of your second model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2DxNn4gl-SCN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5dafbea-10f9-46f9-8612-c5cd4c15c5c5"
      },
      "source": [
        "# Print the best hyperparameters and their associated performance\n",
        "print('Best hyperparameters:', grid_search.best_params_)\n",
        "print('Best cross-validation score:', grid_search.best_score_)\n"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best hyperparameters: {'n_neighbors': 46, 'p': 2, 'weights': 'distance'}\n",
            "Best cross-validation score: 0.7027113981755531\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2D6o6Cy-8xKp"
      },
      "source": [
        "## Challenge 8 Apply your model in the independent test set.\n",
        "User the cells below to apply your two predictive models on the test dataset `M_test` and report testing accuracy for each model.\n",
        "\n",
        "As part of this challenge you are expected to:\n",
        "- Project each observation in the test dataset `M_test` onto the reduced-dimensional features space.\n",
        "- Apply each on of your model to make predict each user's political preference (for users in the testing set only)\n",
        "- Report testing accuracy on each of your models.\n",
        "- Make an assessment as to which model is better and whether either of your models is overfitted or under-fitted."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HtC0osVlCgr4"
      },
      "source": [
        "#Calculate the  product of M_test and the transpose of Vt and assign it to X_test\n",
        "X_test=M_test.dot(Vt.T)\n",
        "\n",
        "#Convert X_test into a DataFrame object and add y_test as a column\n",
        "X_test=pd.DataFrame(X_test)\n",
        "X_test['y']=y_test\n",
        "X_test.head()\n",
        "\n",
        "#Remove rows with null values in the y column\n",
        "X_test=X_test[X_test['y'].isnull()==False]\n",
        "X_test['y'].isnull().value_counts\n",
        "\n",
        "#Assign the y_test column to the y_test variable and drop the y column from X_test\n",
        "y_test=X_test['y']\n",
        "X_test=X_test.drop('y', axis=1)\n"
      ],
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "svm_model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the SVM model on the test set\n",
        "svm_test_acc = svm_model.score(X_test, y_test)\n",
        "\n",
        "print(\"SVM Test accuracy:\", svm_test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ody1xtj6EjJ",
        "outputId": "dbbbcced-c7f7-48bd-a8b4-ba1d0bba5e73"
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM Test accuracy: 0.7692307692307693\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "knn_model = KNeighborsClassifier(n_neighbors=46, weights='distance', p=2)\n",
        "knn_model.fit(X_train,y_train)\n",
        "y_pred = knn_model.predict(X_test)\n",
        "\n",
        "# Calculate the accuracy of the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"KNN Test accuracy: {:.2f}\".format(accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wxRrRi--9VKl",
        "outputId": "1d3b6bc0-2bd5-498a-858e-e14adaf003cf"
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KNN Test accuracy: 0.77\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tqDyqK9qb4Ze"
      },
      "source": [
        "# END OF EXAM/CODE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ha290eSXRT9R"
      },
      "source": [
        "\n",
        "*Copyright Statement*: Copyright © 2020 Christoforou. The materials provided by the instructor of this course, including this notebook, are for the use of the students enrolled in the course. Materials are presented in an educational context for personal use and study and should not be shared, distributed, disseminated or sold in print — or digitally — outside the course without permission. You may not, nor may you knowingly allow others to reproduce or distribute lecture notes, course materials  as well as any of their derivatives without the instructor's express written consent."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dp_ijPXabKsG"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}